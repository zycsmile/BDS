\begin{abstract}

One of the most common inter-DC  communication pattern 
of online service providers is replicating bulk data from 
one DC to multiple DCs. 
While recent work seeks to improve bulk-data 
multicast by optimizing WAN performance, it is necessarily 
incomplete, as it falls short of fully exploring the 
disjoint inter-DC paths that exist in abundance,
as well as servers' capability to store-and-forward data.
%Inspired by the early success of multicast overlay networks, 
To utilize these unexplored opportunities, we 
argue that an application-level multicast overlay network 
is needed to optimally schedule and route data transfers 
on overlay paths.
Despite the promise, introducing multicast overlays in
the context of inter-DC communication poses new challenges,
such as the sheer number of servers and overlay paths 
which renders it untenable to make optimal overlay selections 
in real-time, and a strong need for preventing any delay of 
latency-sensitive traffic caused by multicasting bulk data. 
We present {\em \name}, a near-optimal multicast overlay network 
for bulk data multicast. 
Contrary to the intuition that servers must retain the capability 
to adapt locally in order to scale out, \name demonstrates the 
feasibility of fully centralizing the overlay path selection
and scheduling of data transfers.
The key insight underlying this centralized design is the 
observation that bulk-data transfers tend to last on long 
timescales so they can 
tolerate a slight delay of centralized decision-making 
in the hope of
a closer-to-optimal overlay routing.
Moreover, allocating bandwidth to each data transfer in a 
centralized manner is amenable to eliminating interference of 
bulk-data transfers on latency-sensitive traffic.
%\name is built on design choices:
%(a) fully centralized decision-making in near real-time, and 
%(b) enforcing a clean, dynamic separation of bandwidth.
%While both design choices introduce costs on performance 
%(\name is unable to update decisions in real time or achieve 
%full link utilization), we believe these costs are outweighed by 
%the benefits, such as centralized optimization driven by a global 
%view.
A pilot deployment of \name in one of the largest online
service providers shows that \name achieves 3-5$\times$
speedup over the provider's existing systems, as well
as several widely used overlay routing systems.


%Distributing bulk data across datacenters (DCs) in a timely and
%cost-effective manner is critical to large-scale online service
%providers.
%While recent research has significantly improved the WAN performance
%between DCs, we argue that a multicast overlay network that optimally
%schedules and delivers data in a way that fully exploits available
%overlay paths is essential to achieving desirable performance.
%Drawing on the experience of a large online service providers, we
%observe two requirements of an inter-DC multicast overlay network:
%(1) overlay routing and scheduling needs to be driven by an
%up-to-date global view of data delivery status at all servers, and
%(2) it must prevent delay of latency-sensitive
%traffic caused by bulk data transfers.
%
%This paper presents \name, a near-optimal inter-DC multicast overlay
%network that distributing bulk data.
%At the core of \name are two design choices.
%First, decision making in \name is fully centralized; the \name
%controller directly orchestrates servers to split, reorder, and
%deliver data dynamically along overlay paths, in order to
%circumvent inter-/intra-DC bottlenecks.
%Second, \name enforces a dynamic separation of bandwidth allocated
%for bulk data transfers and latency-sensitive traffic.
%While both design choices introduce costs in performance (i.e.,
%\name is unable to update decisions in real time or achieve full
%link utilization), our design philosophy is that these costs are
%outweighed by the benefits of centralized optimization driven
%by a global view.
%Using a pilot deployment of \name in one of the largest search
%engine service providers, we show that \name achieves 3-5$\times$
%speedup over the provider's existing systems and the techniques
%widely used in today's content delivery networks.


%Drawing on lessons from the decade-long evolution of similar systems in Baidu,
%\name take a centralized approach, which uses a controller to maintains the
%data delivery status in all servers, and update the scheduling and overlay routing
%decisions in near real time by solving a multicommodity flow problem using a
%near-optimal yet efficient algorithm.
%The key insight underlying \name's centralized architecture is the observation that
%the cost of not being able to adapt to network conditions in real time (such as in
%a decentralized system) is greatly outweighed by the benefits of centralized
%control to optimally update overlay routing and scheduling even at a coarse
%timescale (every few seconds), as well as the resulting system that has less
%complexity.

\end{abstract}
