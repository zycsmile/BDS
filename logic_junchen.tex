\section{Near-Optimal and Efficient Decision-Making Logic}
\label{sec:logic}

The key challenge of \name is how to update the overlay routing
in near real-time by finding an optimal solution of an overlay
routing problem at scales of
\fillme overlay paths and \fillme objects.
%At a high level, to optimize inter-DC data multicast, \name fully
%exploits application-level overlay paths by splitting data into
%small blocks and periodically selecting the overlay paths to send
%each data block.
While achieving optimal overlay routing may
indeed be intractable due to the
sheer number of available overlay paths and data blocks,
\name strikes a favorable tradeoff between optimality of solutions
and time to solve the problem.
The key idea here is to {\em decouple} the problem into two steps,
scheduling (i.e., which data blocks to be sent)
and routing (to which servers)
 (\Section\ref{subsec:logic:separation}).
After this logical decoupling, \name can solve both problems
efficiently and near-optimally with proved guarantees
(\Section\ref{subsec:logic:scheduling},~\ref{subsec:logic:routing}).

%At a high level, \name optimizes the data distribution performance by splitting data into fine-grained blocks so as to exploiting all available server-level overlay paths, and possible reordering of blocks to speed up the process.
%In a general case, it is indeed intractable to solve the problem in near real-time, but \name can find a near-optimal solution for our problem scale in several seconds by using applying two approximations: (1) separating the problem of data scheduling and overlay routing, and (2) using standard linear-programming relaxation to solve them efficiently.

%\jc{In general, please avoid use of big formulations (like eq 5-10 on p6). May strike a negative impression in nsdi submissions}

\subsection{Basic formulation}
\label{subsec:logic:formulation}

%\begin{table}[t]
%\begin{center}
%%\resizebox{\textwidth/2}{!}{
%%\begin{tabular}{p{2cm}<{\centering}|p{2cm}<{\centering}}
%\begin{tabular}{| c | l|}
%\hline
% \rowcolor[gray]{0.9}
%\textbf{Variables} & \textbf{Meaning} \\
%\hline \hline
%\textit{$\mathbb{A}$} & Set of all $(s, d)$ pair\\
%\hline
%\textit{$\mathbb{B}$} & Set of blocks of all tasks\\
%\hline
%\textit{$B_{i,j}$} & Block $i$ in Task $j$\\
%\hline
%\textit{$c(l_{u,v})$} & Capacity of link $l_{u,v}$\\
%\hline
%\textit{$Path(s,d)$} & Set of all potential paths in $\mathbb{A}$\\
%\hline
%\textit{$f_{B_{i,j},p_\lambda}$} & Allocated bandwidth for $B_{i,j}$ on path $p_\lambda$\\
%\hline
%\textit{$I_{B_{i,j},p_\lambda}$} & 0 or 1: whether $p_\lambda$ is selected for $B_{i,j}$\\
%\hline
%\end{tabular}
%%}
%\end{center}
%\caption{Variables in \name.}
%\label{table:para}
%\end{table}

We start with the basic formulation of overlay routing in \name,
first under network capacity and multicast
transfers are fixed, and then extending it to
handle dynamic changes in network performance and request arrivals.

\mypara{Under fixed network capacity}
Suppose the network capacity is fixed, the problem of multicast
overlay routing can be formulated as following:
%The data distribution problem over inter-DC WANs is defined as follows: We are given one data source DC $S$ and sets of destinations DC $D=\{d_i\}$ in an overlay network, what's the optimal transmission strategy with shortest completion time under a serious of constraints. To formulate this problem and design the decision-making logic for the centralized controller, we should first clarify the following aspects (Table \ref{table:para} summarizes some key variables used in \name):

%\jc{Notions are too complicated. Please simplify. 4.1 should be at most 1/3 pg.}

\noindent(1) {\em Input.}
One source DC, sets of destinations DC,
network topology,
server upload (and download) rate limit,
link capacity.
We name a data transmission a {\em task} $T$, which is split into
many smaller fixed-sized {\em blocks}, and the $i$th block of task $j$ is denoted as $B_{i,j}$ (By default, the block size is 2M, for efficient transmission and acceptable calculation overhead).

\noindent(2) {\em Output.} A four tuple for each server: $\langle \overrightarrow{o_B}, s_{B}^*, p_{B}^*, f^*_{B,p_{B}^*} \rangle$, which denotes the block transmission sequence, the optimal source and overlay path for each block, and the optimal allocated bandwidth on this path, respectively.

\noindent(3) {\em Constraints.}
There are four constraints on link capacity, file size, bandwidth allocation and path selection:

%The mentioned three constraints can then be formulated as follows:
\begin{packeditemize}
\item Link capacity. The summed allocated bandwidth on this path should be no more than its capacity $c(p_\lambda)$, where $I_{B_{i,j},p_\lambda}$ denotes whether $p_\lambda$ is selected for $B_{i,j}$
\begin{equation}
%\begin{split}
c(p_\lambda) \geq  \displaystyle{\sum_{(s,d)\in \mathbb{A}}} \displaystyle{\sum_{B_{i,j} \in \mathbb{B}}} f_{B_{i,j},p_\lambda} \cdot I_{B_{i,j},p_\lambda}\\
%& \forall p_\lambda \in Path(s,d) \label{st:capacity}
%\end{split}
\end{equation}

\item Data size constraint. The sum of allocated bandwidth should be no less than its size $\mathbb{S}(B_{i,j})$.
\begin{equation}
%\begin{split}
\mathbb{S}(B_{i,j}) \leq  \displaystyle{\sum_{(s,d)\in \mathbb{A}}} \displaystyle{\sum_{p_{\lambda}\in Path(s,d)}} f_{B_{i,j},p_\lambda} \cdot I_{B_{i,j},p_\lambda} \cdot \Delta T\\
%& \forall B_{i,j} \in \mathbb{B} \label{st:size}\\
%\end{split}
\end{equation}

\item Bandwidth constraint. The allocated bandwidth on path $p_\lambda$ should be the minimum of three parameters: link capacity $c(p_\lambda)$, source server upload rate $R_{up}(s)$, destination server download rate $R_{down}(d)$.
\begin{equation}
%\begin{split}
f_{B_{i,j},p_\lambda} \leq  min \{c(p_\lambda),R_{up}(s),R_{down}(d)\}\\
%& \forall p_\lambda \in Path(s,d) \label{st:bottleneck}
%\end{split}
\end{equation}

\item Path selection: Only one path will be chosen for a particular block.
$\displaystyle{\sum_{p_\lambda \in Path(s,d)}} I_{B_{i,j},p_\lambda} = 1$
\end{packeditemize}
%\jc{maybe it's better in math after all. please write
%it in math and add comments in the end to describe the
%meaning}
%%The link capacity constraint takes effect on any arbitrary link $l_{u,v}$:
%for each link $l_{u,v}$,
%the summed allocated bandwidth on this path should be
%no more than its capacity $c(l_{u,v})$,
%and for each path $p_\lambda$, the available capacity
%$c(p_\lambda)$ should be no more than the minimum
%capacity of the consisting links.
%%The path capacity constraint takes effect on path $p_\lambda$: the available capacity $c(p_\lambda)$ should be no more than the minimum capacity of the consisting links.
%The data size constraint takes effect on blocks: the sum of allocated bandwidth should be no less than its size. The bandwidth constraint defines the allocated bandwidth for $B_{i,j}$ on $p_\lambda$: $f^*_{B_{i,j},p_{B_{i,j}}}$ should be no more than the minimum of the following three parameters: path capacity $c(p_\lambda)$, the upload rate of source node $R_{up}(s)$ and the download rate of destination node $R_{down}(d)$.

\noindent(4) {\em Objective function.} To speed up the bulk data distribution, \name aims at maximizing the allocated weighted bandwidth for all the blocks over all the paths.

\begin{equation}
\centering
max \quad \displaystyle{\sum_{(s,d)\in \mathbb{A}}} \displaystyle{\sum_{B_{i,j} \in \mathbb{B}}} \displaystyle{\sum_{p_{\lambda}\in Path(s,d)}} w(B_{i,j})\cdot f_{B_{i,j},p_\lambda} \cdot I_{B_{i,j},p_\lambda}
\label{equation:objective}
\end{equation}
where $w(B_{i,j}) = \frac{pr_j}{2^{D_j-t}}$ is the weight of $B_{i,j}$, similar to \cite{zhang2015guarantee}, $pr_j$ is the priority of Task $j$, $D_j$ is the deadline and $t$ is the current time.

\mypara{Dynamic updates}
Since any change in network performance or arrival of
new requests may potentially alter the optimal overlay
routing decisions,
%The problem can be formulated precisely according to the above definitions only when the network is static and all the conditions stay unchanged during the whole transmission period. However, it is impractical to make such assumptions because bulk data transfer and constantly changing online traffic co-exists in the network and the design choice of \name is to make dynamic bandwidth separation. Therefore,
so \name should react to the changing network conditions by monitoring residual bandwidth and re-configured the above formulation (By default, \name tries to update network information and resolve the problem every 3 seconds, and the cycle length is also evaluated in \Section\ref{subsubsec:evaluation:depth}). Unfortunately, the origin problem becomes considerably complex and hard to solve when making re-formulation, because there will be multiple optional data sources for any arbitrary task. Thus, the searching space grows exponentially and it becomes impossible to find out the optimal transmission. To make it solvable, \name decouples the problem into two parts and tries to find the optimal solutions for each procedure.

%\jc{a missing piece is how large each block is, and why. }

\subsection{Decoupling scheduling and routing}
\label{subsec:logic:separation}

The key insight underlying the above re-formulated problem is the
separation of data scheduling and overlay routing: the scheduling procedure selects a subset of blocks to be transferred first
($\overrightarrow{o_B}$), and the subsequent routing procedure determines the routing paths ($p_{B_{i,j}}^*$) and allocated bandwidth ($f^*_{B_{i,j},p_{B_{i,j}}^*}$) to these blocks.

This decoupling reduces the computational complexity on the centralized controller side. As the scheduling stage selects a subset of blocks, and only these selected blocks will be routed and transferred in the following routing stage, the searching spaces are thus significantly reduced for the subsequent routing procedure, speeding up the execution of the centralized algorithm.

What worth mentioning is that such decoupling is near-optimal. For the origin bulk data transfer problem, the optimal solution is to decide the optimal block transmission order $\overrightarrow{o_B}$ for all servers, while such decoupling converts this optimal solution into an equivalent one: to decide the optimal order to transmit the selected blocks in each scheduling cycle (so as to enforce network dynamic updates). Thus, the decoupling introduces no degradation as long as \name finds the optimal solutions for both of the scheduling and routing procedures in each cycle.

In the existing hybrid CDN and P2P architecture \cite{yin2009design} or centralized P2P scheme \cite{lee2003centralized}, there are also centralized servers with global information, but those servers are used for specific tasks (like system bootstrapping and maintaining global index) \cite{androutsellis2004survey}. While the centralized controller of \name faces more challenges in terms of real-time computing. The above mentioned decoupling could not only sense the changing network conditions, but also reduce the calculation scale of the centralized algorithm running on the controller.
%uses the global information to decouple scheduling and routing without introducing degradation.\jc{put the last sentence after the benefits. also, i don't get the point of this sentence.}
%, i.e., outputting the block transmission order $\overrightarrow{o}(s_i)$ ; the overlay routing procedure aims at make optimal routing strategies (assign $s_{B_{i,j}}^*$, $p_{B_{i,j}}^*$ and $f^*_{B_{i,j},p_{B_{i,j}}^*}$) for all selected blocks $B_{i,j}$ in the overlay network.
%There are two main benefits of this separation.
%\begin{packedenumerate}
%\item It reduces the computational complexity on the centralized controller side. The objective of the separated scheduling stage is to select a subset of blocks, and only these selected blocks will be routed and transferred in the following routing stage. So the separated data scheduling could avoid exploring unnecessary searching spaces for those unselected blocks.
%\item It speeds up the overall data distribution. This advantage comes from the customized block selection scheme that picks out a specific subset of blocks so as to reduce the overall completion time.
%\jc{why this is a benefit of decoupling? seems an advantage of centralized control?}
%\end{packedenumerate}
%
%\mypara{Why such decoupling is near-optimal}
%The optimal solution for the origin bulk data transfer problem is to decide the optimal order $\overrightarrow{o}(s_i)$ to transmit block for all servers, while such decoupling converts the origin problem into an equivalent one: to decide the optimal order to transmit the selected blocks in each scheduling cycle (so as to enforce network dynamic updates). Thus, the decoupling introduces no degradation as long as \name finds the optimal solutions for both of the scheduling and routing procedures.
%
%\jc{how about the following flow:
%para1: what the decoupling means; \\
%para2: why it saves costs; \\
%para3: why it could be near-optimal;\\
%para4: why people haven't thought about this or why our solution is unique}

%\jc{still unclear why this decoupling is efficient and near optimal}

\subsection{Scheduling}
\label{subsec:logic:scheduling}

The scheduling stage aims at selecting a subset of blocks to reduce searching space, i.e., \name should select a subset of blocks that should be transferred first and output the transmission order $\overrightarrow{o}(s_i)$ for all the servers $s_i$.

The key to avoid introducing degradation in this procedure is to make sure that the optimal result is still retained in the reduced searching spaces, in other words, the optimal result is not in the space that is pruned by scheduling procedure. We claim that balancing the duplication number of all blocks is the key concern and the optimal scheduling result is yield from the situation that all the blocks are balanced duplicated. So in the scheduling procedure, \name prunes the searching space that will not result in balanced duplications. Therefore, the scheduling procedure selects the least duplicated blocks to transmit first to make block duplications more balanced and ignore the most duplicated blocks in the recent scheduling cycle. In this way, the optimal result will thus be retained in the reduced searching spaces.
%\jc{this is a key statement! please make it more precisely}

To be specific, assume the origin bulk data in the source DC is split into $n$ blocks, and there are $2m$ DCs in the WAN. Different scheduling strategies will select different block subsets and lead to different intermediate transmission states, finally resulting in different completion time. Take two intermediate states as examples: 1) All of the $n$ blocks has $k$ duplicates; 2) Some of these $n$ blocks have $k1$ $(k1<k)$ duplicates and other blocks have $k2$ $(k2>k)$ duplicates. Let $t_1$ denote the completion time of case 1 and $t_2$ denote that of case 2, we have: $t_2 > t_1$ (See Appendix for the proof). So in the data scheduling stage, \name will firstly pick out the subset of blocks with the least downloaded duplicates, to balance the block duplications.

%\jc{isn't it trivial to maintain the counters?}
%For efficient selection, \name keeps a counter $c_i$ in the controller for each block and updates it once receiving finish notifications from receivers. The scheduling stage always gives priority to the smallest $c_i$. For efficient processing, \name keeps all the counters $c_i$ in a doubly linked list in an ascending order of their values. For each download, the controller selects the top item in the list (the smallest value) to be downloaded. The controller listens and serves an HTTP port, once receiving a transmission completion signal from receivers, it updates the corresponding block's counter value and adjusts its position in the linked list for further processing.

\subsection{Routing}
\label{subsec:logic:routing}

In the overlay routing stage, \name routes and transfers blocks according to $\overrightarrow{o}(s_i)$, the output of data scheduling stage, and then tries to make optimal routing strategy (assign $s_{B_{i,j}}^*$, $p_{B_{i,j}}^*$ and $f^*_{B_{i,j},p_{B_{i,j}}^*}$) for each block $B_{i,j}$. Note that there are multiple potential data sources for each block in the multicast overlay network, so the objective of routing is to select the most efficient data source and assign intermediate paths to all blocks, and then calculate the bandwidth allocation on those selected paths.

With the constraints described in \Section\ref{subsec:logic:formulation}, this formulation in Equation \ref{equation:objective} is an integer multi-commodity flow algorithm which is known to be NP-complete \cite{garg1997primal}, and there is no known algorithm to find an optimal solution. To make this problem solvable, we look into it from a different perspective. As the size of a task is dozens of TBs to PBs, while each block is just about several MBs, we can approximate tasks as they are infinitesimally split and can be transferred to a set of possible paths between the source DC and the destination DC. So it is possible to solve this problem by a linear programming (LP) relaxation which can be transformed to a maximum concurrent flow (MCF) problem \cite{garg2007faster,reed2012traffic}, and the relaxed problem aims at transferring at least a fraction $\alpha$ of each transmission. Such MCF problem provides a solution to the original NP-complete problem, although with fractional flows. Specifically, the optimum value $F^*$ in the MCF problem is equivalent to that of the original problem $f^*$ with a relationship given by $F^* / \alpha = f^*$. Thus, the original problem is thus converted to maximize $\alpha$ and can be solved within polynomial time.

However, the number of blocks will grow considerably large when splitting tasks infinitesimally, and this will lead to intolerable computing time on the controller side. There are two coping strategies on this problem: on one hand, \name merges the blocks with the same source and destination pair into one subtask so as to reduce the calculation scale; on the other hand, \name adopts the improved fully polynomial-time approximation schemes (FPTAS) by Fleischer \cite{fleischer2000approximating} to optimize the dual problem of the origin problem and works out an $\epsilon$-optimal solution (see Appendix II for the proof of near optimality of \name).% with $\alpha' \geq \alpha_\epsilon \geq \alpha'(1-\epsilon)^{-3}$. This algorithm optimizes the dual problem of the relaxed LP problem by proceeding in phases and iterations
%\jc{sorry, but i'm totally lost. what's the key idea? is it just a standard LP relaxation?}
