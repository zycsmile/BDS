\section{Overview of \name}
\label{sec:overview}

To optimize inter-DC multicasts, while minimizing interference with 
latency-sensitive traffic, we present {\em \name}, a {\em fully centralized} 
near-optimal application-level overlay network for inter-DC multicast. 
Before presenting \name in details, we first highlight the intuitions 
behind its design choices, and the challenges to make it practical.


\mypara{Centralized control}
Conventional wisdom on wide-area overlay networks has relied, to 
some extent, on {\em local} adaptation of individual nodes (or 
relay servers) to achieve desirable scalability and responsiveness 
to network dynamics 
(e.g.,~\cite{Andreev2013Designing,Repantis2010Scaling,Huang2014A,mukerjee2014enabling}),
despite the resulting suboptimal performance due to lack of global 
view or orchestration. 
%Recent work (e.g.,~\cite{mukerjee2014enabling}), however,
%shows the feasibility of combining
%local adaptation with a centralized logic operating
%on coarse timescales.
In contrast, \name takes an explicit stance that it is practical to 
fully centralize the control of an wide-area overlay networks and 
still achieve near-optimal performance in the setting of inter-DC 
multicasts. \name coincide with parallel recent work of centralizing
management of large-scale distributed systems, e.g.,~\cite{gog2016firmament}
At a high level, \name uses a centralized controller that 
periodically pulls information (e.g., data delivery status) from all 
servers, updates the decisions regarding overlay routing, and pushes 
them to agents running locally on servers 
(Figure~\ref{fig:framework}).
Note that when the controller fails or is unreachable, \name will 
fall back to a decentralized control scheme to ensure graceful 
performance degradation to local adaptation 
(\Section\ref{subsec:system:fault}).

\begin{figure}[t]
  \centering
  %\includegraphics[width=2in]{images/framework.eps}
  \includegraphics[width=2.3in]{images/framework-new.pdf}
    \vspace{-0.2cm}
  \tightcaption{The centralized design of \name.}
  \label{fig:framework}
\vspace{-0.4cm}
\end{figure}

\name's centralized design is driven by several empirical observations:
\begin{packedenumerate}

\item {\em Large decision space:}
The sheer amount of inter-DC overlay paths (which grow exponentially
with more servers acting as overlay nodes) makes it difficult for 
individual servers to explore all available overlay paths based only 
on local measurements. In contrast, we could significantly improve 
overlay multicast performance by maintaining a global view of data 
delivery status of all servers, and dynamically balancing the 
availability of various data blocks, which turns out to be critical 
to achieving near-optimal performance 
(\Section\ref{subsec:logic:scheduling}).

\item {\em Large data size:}
Unlike latency-sensitive traffic (e.g., search queries) which lasts 
on timescales of several to 10s of milliseconds, inter-DC multicasts 
last on much coarser timescales.
%Thus, it is a necessary requirement to be continously adaptive to 
%any transient network dynamics.
%In this context, the tradeoff between a centralized design and a decentralized one is that centralized control essentially trades real-time responsiveness to network dynamics for closer-to-optimal control decisions driven by a global view of data delivery. Here,
Therefore, \name can tolerate a short delay (of a few seconds) in order
to get better routing decisions from a centralized controller which 
maintains a global view of data delivery and is capable of orchestrating
all overlay servers.

\item {\em Strict traffic isolation:}
As observed in \Section\ref{subsec:motivation:baseline}, it is vital 
that inter-DC multicasts avoid hotspots and excessive bandwidth usage 
that negatively impact the latency of delay-sensitive traffic, but 
it is difficult to prevent such situations without any coordination 
across overlay servers. In contrast, it is mechanically simpler to 
allocate bandwidth of each data transfer by directing setting the 
sending rate at all servers in a centralized fashion 
(\Section\ref{sec:system}).

\item {\em Lower engineering complexity:}
Conceptually, the centralized architecture moves the control 
complexity to the centralized controller, making \name amenable to a
simpler implementation, in which the control logic running locally in
each server can be stateless and triggered only on arrivals of new 
data units or control messages.

\end{packedenumerate}

%\mypara{Fast and near-optimal decision-making}
\mypara{The key to realizing centralized control}
In essence, \name trades slight update delay for the closer-to-optimal 
decisions in a centralized fashion. Thus, the key to striking such a 
favorable balance is a near-optimal yet efficient overlay routing 
algorithm that can update decisions in near realtime. At a first 
glance, this is indeed intractable. For the workload at a scale of 
\company, the centralized overlay routing algorithm must pick the next 
hops for $10^5$s of blocks from $10^4$s of servers, a scale that 
could grow exponentially when we consider the number of possible 
overlay paths that go through these servers as well as finer-grained 
block partitions. With the standard routing formulation and linear 
programming solvers, it could be completely unrealistic to make 
optimal solutions by exploring such a large decision space 
(\Section\ref{subsubsec:evaluation:depth}).
The next section will present how \name addresses this challenge.

